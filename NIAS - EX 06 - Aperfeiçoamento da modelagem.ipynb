{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ntrain = pd.read_csv('../input/titanic/train.csv')\ntest = pd.read_csv('../input/titanic/test.csv')\n\ntrain_new = train.drop(['Name', 'Ticket', 'Cabin', 'PassengerId'], axis=1)\ntest_new = test.drop(['Name', 'Ticket', 'Cabin', 'PassengerId'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T19:24:06.311386Z","iopub.execute_input":"2022-01-09T19:24:06.311654Z","iopub.status.idle":"2022-01-09T19:24:06.331822Z","shell.execute_reply.started":"2022-01-09T19:24:06.311624Z","shell.execute_reply":"2022-01-09T19:24:06.330959Z"},"trusted":true},"execution_count":233,"outputs":[]},{"cell_type":"code","source":"train_copy = train_new.copy()\ntest_copy = test_new.copy()\n\ntrain_new['Age'].fillna(method='ffill', inplace=True)\ntest_new['Age'].fillna(method='ffill', inplace=True)\ntrain_new['Embarked'].fillna(method='ffill', inplace=True)\n\ntest_new['Age_Intervals'] = pd.cut(test_new['Age'], bins=5)\ntrain_new['Age_Intervals'] = pd.cut(train_new['Age'], bins=5)\n\ntrain_new_copy = train_new.copy()\ntest_new_copy = test_new.copy()\ntrain_new.info()\n#test.info()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T19:24:06.333701Z","iopub.execute_input":"2022-01-09T19:24:06.333990Z","iopub.status.idle":"2022-01-09T19:24:06.358934Z","shell.execute_reply.started":"2022-01-09T19:24:06.333956Z","shell.execute_reply":"2022-01-09T19:24:06.358195Z"},"trusted":true},"execution_count":234,"outputs":[]},{"cell_type":"markdown","source":"**01 - Encoding de Variáveis Categóricas**","metadata":{}},{"cell_type":"code","source":"def indent(db, typ):\n    p = (db.dtypes == typ)\n    return list(p[p].index)\n\ns = indent(train_new, 'object')\nn = indent(train_new, 'float64')\nd = indent(train_new, 'int64')\nprint('Variáveis categóricas:\\n %s\\nVariáveis Númericas:\\n %s' %(s, n+d))\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-09T19:24:06.359914Z","iopub.execute_input":"2022-01-09T19:24:06.360341Z","iopub.status.idle":"2022-01-09T19:24:06.367769Z","shell.execute_reply.started":"2022-01-09T19:24:06.360306Z","shell.execute_reply":"2022-01-09T19:24:06.367184Z"},"trusted":true},"execution_count":235,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\n\ndef ONEHOT(db, obj):\n    for x in obj:\n        if db[x].dtypes == 'object':\n            label_encod = LabelEncoder()\n            label_bd = label_encod.fit_transform(db[x])\n            \n            Onehotencod = OneHotEncoder(sparse=False)\n            db[x] = Onehotencod.fit_transform(label_bd.reshape(len(label_bd),1))\n            \n        elif (db[x].dtypes != 'object') and (db[x].dtypes != 'float64') and (db[x].dtypes != 'int64'):\n            label_encod = LabelEncoder()\n            db[x] = label_encod.fit_transform(db[x])\n       \nONEHOT(train_new, s + ['Age_Intervals'])\nONEHOT(test_new, s  + ['Age_Intervals'])","metadata":{"execution":{"iopub.status.busy":"2022-01-09T19:24:06.368938Z","iopub.execute_input":"2022-01-09T19:24:06.369277Z","iopub.status.idle":"2022-01-09T19:24:06.396201Z","shell.execute_reply.started":"2022-01-09T19:24:06.369235Z","shell.execute_reply":"2022-01-09T19:24:06.395512Z"},"trusted":true},"execution_count":236,"outputs":[]},{"cell_type":"markdown","source":"**02 - Encoding de Variáveis Categóricas**\n\n**Com os BDs Criados vamos pegar e agora treinar eles**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nY = train_new['Survived']\nX = train_new.drop(['Survived'], axis=1)\n\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size= 0.2)\n\nmodel = RandomForestClassifier()\nmodel.fit(X_train,Y_train)\n\npredict = model.predict(X_test)\n\nscore = accuracy_score(Y_test, predict)\nprint(score)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T19:24:06.397918Z","iopub.execute_input":"2022-01-09T19:24:06.398266Z","iopub.status.idle":"2022-01-09T19:24:06.651100Z","shell.execute_reply.started":"2022-01-09T19:24:06.398237Z","shell.execute_reply":"2022-01-09T19:24:06.649630Z"},"trusted":true},"execution_count":237,"outputs":[]},{"cell_type":"markdown","source":"**01 - Pipelines**","metadata":{}},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n\ntrain_new = train_copy\ntest_new = test_copy","metadata":{"execution":{"iopub.status.busy":"2022-01-09T19:24:06.652547Z","iopub.execute_input":"2022-01-09T19:24:06.653052Z","iopub.status.idle":"2022-01-09T19:24:06.658966Z","shell.execute_reply.started":"2022-01-09T19:24:06.653006Z","shell.execute_reply":"2022-01-09T19:24:06.658282Z"},"trusted":true},"execution_count":238,"outputs":[]},{"cell_type":"markdown","source":"● data: Banco de dados a partir do qual será produzido o modelo.\n\n● encoder: a estratégia de encoding de variáveis categóricas,\ncomo one-hot ou label encoder.\n\n● model: o algoritmo que irá produzir o modelo, inicialmente será\no random forest classifier.\n\n● numerical_imputer: a estratégia usada para substituir valores\nnulos nas features numéricas, como \"mean\" ou \"median\".\n\n● categorical_imputer: estratégia para preencher valores nulos\nnas features categóricas, aqui será usada apenas \"mostfrequent\", \nque é substituir pelo valor que mais aparece no banco\nde dados.","metadata":{}},{"cell_type":"code","source":"def pipelin(db, encoder, model, numerical_imputer = SimpleImputer(), categorical_imputer = SimpleImputer(strategy= 'most_frequent')):\n    Y_new = db['Survived']\n    X_new = db.drop(['Survived'], axis = 1)\n    \n    X_train_new, X_test_new, Y_train_new, Y_test_new = train_test_split(X_new, Y_new, test_size = 0.2)\n    \n    numerical_cols = n + d\n    \n    categorical_transform = Pipeline(steps=[('imputer', categorical_imputer), ('encoder', encoder)])\n    \n    preprocessor = ColumnTransformer(transformers=[('num', numerical_imputer, numerical_cols), ('cat', categorical_transform, s)])\n    \n    pipeline_test = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n    \n    pipeline_test.fit(X_train_new, Y_train_new)\n    \n    pipe_predict = pipeline_test.predict(X_test_new)\n    \n    score = accuracy_score(Y_test_new, pipe_predict)\n    \n    return round(score*100, 4)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-09T19:24:06.660379Z","iopub.execute_input":"2022-01-09T19:24:06.660878Z","iopub.status.idle":"2022-01-09T19:24:06.674330Z","shell.execute_reply.started":"2022-01-09T19:24:06.660834Z","shell.execute_reply":"2022-01-09T19:24:06.673532Z"},"trusted":true},"execution_count":239,"outputs":[]},{"cell_type":"markdown","source":"**03 - Pipelines**","metadata":{}},{"cell_type":"code","source":"train_new.info()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T19:24:06.675936Z","iopub.execute_input":"2022-01-09T19:24:06.676821Z","iopub.status.idle":"2022-01-09T19:24:06.701534Z","shell.execute_reply.started":"2022-01-09T19:24:06.676769Z","shell.execute_reply":"2022-01-09T19:24:06.700824Z"},"trusted":true},"execution_count":240,"outputs":[]},{"cell_type":"code","source":"mean = SimpleImputer(strategy='mean')\nmost_frequent = SimpleImputer(strategy='most_frequent')\nmedian = SimpleImputer(strategy='median')\nzero = SimpleImputer(strategy='constant', fill_value = 0)\n\none_hot_encoder = OneHotEncoder(sparse=False)\nordinal_encoder = OrdinalEncoder()\n\ntypes_of_encoders = [one_hot_encoder, ordinal_encoder]\ntypes_of_infos = [mean, most_frequent, median, zero]\n\nd.pop(0)\nfor encods in types_of_encoders:\n    for infos in types_of_infos:\n        score = pipelin(train_new, encods, RandomForestClassifier(), numerical_imputer = infos)\n        print('Encoder -> %s, temos uma porcentagem de: %s, para o numerical imputer: %s' %(str(encods), str(score), str(infos)))","metadata":{"execution":{"iopub.status.busy":"2022-01-09T19:24:06.703025Z","iopub.execute_input":"2022-01-09T19:24:06.703526Z","iopub.status.idle":"2022-01-09T19:24:08.860586Z","shell.execute_reply.started":"2022-01-09T19:24:06.703479Z","shell.execute_reply":"2022-01-09T19:24:08.859677Z"},"trusted":true},"execution_count":241,"outputs":[]},{"cell_type":"markdown","source":"**01 - Cross Validation e Gradient Boosting**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import cross_val_score\n\nONEHOT(train_new_copy, s + ['Age_Intervals'])\nONEHOT(test_new_copy, s  + ['Age_Intervals'])\n\ndef gradboostingclass(db, X, Y):\n    p = cross_val_score(db, X, Y, cv = 5, scoring = \"accuracy\")\n    return(round(p.mean() * 100, 4))\n    \ngradientboostclassi = GradientBoostingClassifier(random_state = 0, n_iter_no_change = 100)\n\nY_new_copy = train_new_copy['Survived']\nX_new_copy = train_new_copy.drop(['Survived'],axis=1)\n\nX_new_train, X_new_test, Y_new_train,Y_new_test = train_test_split(X_new_copy, Y_new_copy, test_size=0.2)\n\ngradientboostclassi.fit(X_new_train, Y_new_train)\n\nscore = gradboostingclass(gradientboostclassi, X_new_test, Y_new_test)\nprint('Porcentagem usando Gradient Boosting Classifier: %s' % str(score))","metadata":{"execution":{"iopub.status.busy":"2022-01-09T19:24:08.862311Z","iopub.execute_input":"2022-01-09T19:24:08.862598Z","iopub.status.idle":"2022-01-09T19:24:09.414647Z","shell.execute_reply.started":"2022-01-09T19:24:08.862565Z","shell.execute_reply":"2022-01-09T19:24:09.413661Z"},"trusted":true},"execution_count":242,"outputs":[]}]}